<!DOCTYPE html>
<html>
  <head>
  	<meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Build and Test Conflicts in The Wild</title>
    
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600&amp;subset=latin-ext" rel="stylesheet">
    
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="style.css" rel="stylesheet">
    <script src="http://www.w3schools.com/lib/w3data.js"></script>
    <script>
        $(function(){
            $("#includedContent").load("content.html");
        });
    </script>
  </head>
  <body style="font-family:verdana;">
    <header>
      <div class="top">
		  <div class="container">
		      <div class="row">
		          <div class="col-sm-6">
		              <p>Build and Test Conflicts in The Wild</p>
		          </div>
		      </div>
		  </div>
		</div>
		<nav class="navbar navbar-default">
			<div class="container">
			<div class="collapse navbar-collapse" id="bs-navbar-collapse">
		    	<ul class="nav navbar-nav main-navbar-nav">
		        	<li class="active"><a href="main.html" title="">HOME</a></li>
		        	<li class="dropdown">
		            	<a href="#" title="" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Conflicts <span class="caret"></span></a>
		            	<ul class="dropdown-menu">
		                	<li><a href="build-conflicts.html" title="">Build Conflicts</a></li>
		                	<li><a href="test-conflicts.html" title="">Test Conflicts</a></li>
		            	</ul>
		        	</li>
		        	<li><a href="sample.html" title="">Sample</a></li>
		    	</ul>                           
			</div>        
			</div>
		</nav>
    </header>
    <div class="bread_area">
      <div class="container">
          <div class="row">
              <div class="col-sm-12">
                   <ol class="breadcrumb">
                      <li><a href="main.html">Home</a></li>
                      <li class="active">Checking Test Conflicts</li>
                  </ol>                  
              </div>
          </div>
      </div>
    </div>
    <main class="site-main page-main">
        <div class="container">
            <div class="row">
                <section class="page col-sm-9">
                  <h2>Checking Test Conflicts</h2>
                  <div class="abstract"> 
                    <i>Failed</i> builds might have many causes. In this section, we discuss how we classify <i>failed</i> builds caused by conflicting contributions involving in a merge scenario. We identify two categories of test conflicts: failed test cases and unachieved coverage. Like the approach adopted to classify build conflicts, we also adopt syntatic diffs to get information about the parents contributions. For that we improved GumTree tool to have more information about the changes (source code available <a href="https://github.com/build-test-conflicts/gumtree" title="">here</a>)
                  </div>
				    </div>

          <div class="study">
            <h3>Failed Test Cases</h3>
            <p> Problems during the testing phase of a build process are often caused by failed test cases, which may be motivated by failures as also errors during the test execution. Failures represent an unexpected software behavior, while errors represent the incapability of executing a test case due to unexpected operations. For a failed build, Travis log reports the failed test case and its associated class. </p>
			
            <p>To ensure test case failure occurs because of the intersection of parent’s contributions and not by external causes, we decided to individually execute each failed test case again. To evaluate whether the methods and classes exercised during the execution are also changed by the parents commits, we also analyze the coverage of this individual re-execution of the failed test case (using syntactic diffs). If a failed test case exercises source code changed during parent’s contributions, these changes might have a direct impact in the unexpected software behaviour. </p>

            <p>Our scripts analyze the Travis log identifying the failed test case and the associated class. With such information, we use Travis to perform a new build process that is done in two phases: (i) test case execution and (ii) analysis of code coverage and parent’s contributions.</p>

            <div class="conflict">
              <h4> Test Case Execution </h4>
              <p> Since for computing code coverage information, one has to change configuration files adding a new dependency for a tool responsible for generating the coverage. Additionally, it is necessary to deploy this information out of Travis environment. So our scripts reset the head of the our fork project to point to the merge commit associated with the failed build and adapt the configuration files to our needs (coverage generation and deployment on GitHub using tags for each commit). After the test case execution, we instrument our scripts to save the coverage associated with each test case in GitHub.
            </div>

            <div class="conflict">
              <h4> Code Coverage and Parent's Contributions</h4>
              <p> There are two types of changes we can evaluate about the classes changed by parent’s contributions: class structure or methods. For getting class structure changes, we consider any change done in a class, which can be identified through the original GumTree report. Although GumTree presents all changes performed between two files, it does not associate the changes with their methods. Nevertheless, to perform part of this analysis in this step, our scripts must know the changed methods. To solve this issue, we improve the <a href="https://github.com/build-test-conflicts/gumtree" target="_blank">GumTree tool</a> report by adding the information of related methods into diff reports when it applies.
            </div>

             <div class="study">
            	<h4>Checking contributions</h4>
            	<p>Thus, we have information that allow us to verify dependencies between parent's contributions. Based in these information, we analyse the coverage results and the files changes during parent’s contributions looking for two types of dependency, as presented in Figure 1, bellow. Orange and blue circumferences represent the set of changed classes by each parent, while yellow the set of exercised classes by the test case. (A) Intersection among exercised and changed parents classes. (B) Intersection between exercised and changed classes for each parent.</p>
            	<div class="container">
              	<figure>
                	<img src="img/test-conflicts-approach.png" alt="Study Design" width="250" height="200" title="Study Design">
                	<figcaption>Figure 1 - Checking dependencies between parent's contributions.</figcaption>
                </figure>
              </div>
            </div>
            <p>Additionally, we verify whether changes happen in the failed test cases leading us to consider interferences between changed classes and test cases (new, changed or old test cases).</p>
        </div>

            
        <div class="study">
            <h3>Unachived Coverage Metric</h3>
            <p>The other type of test conflict we consider is related to coverage metrics on source code that is done after the test execution. In this situation, the coverage metrics established for the project are not achieved. For example, in <a href="https://travis-ci.org/jwtk/jjwt/builds/280062604" title="" target="_blank">JJWT</a> project, the coverage metric defined previously for the project is not achieved, as presented bellow. </p>
            
            <br>
              <p style="border:3px; border-style:solid; border-color:#blue; padding: 1em; height: 140px; width: 500px;"> 
                  <span style="color: red;"> Build failed to meet Clover coverage targets: The following coverage targets for null were not met: </span> <br>
                  [ERROR] Total coverage of <span style="color: red;">93.3%</span> did not meet target of <span style="color: red;">100%</span> <br>
                  [ERROR] Method coverage of <span style="color: red;">95%</span> did not meet target of <span style="color: red;">100%</span><br>
                  [ERROR] Statement coverage of <span style="color: red;">92.5%</span> did not meet target of <span style="color: red;">100%</span><br>
                  [ERROR] Conditional coverage of <span style="color: red;">94.4%</span> did not meet target of <span style="color: red;">100%</span><br>
            <br>

            <p> For these scenarios, we do not run any test case since the conflict happens due to the not-achievement of the metric defined previously. To rerun the test suit would produce the same coverage results ensuring the test conflict.
        </div>

    </main>
    <footer>
      <div class="container">
        <div class="cen">
            <div class="col-md-12">
                
            </div>
        </div>
      </div>
      <div id="copyright">
            <div class="container">
                <div class="cen">
                    <div class="col-md-8">
                        
                    </div>
                </div>
            </div>
        </div>
    </footer>
    </body>
  </html>
